{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriel-picussa/MVP-de-SSD---Gabriel-Picussa/blob/main/MVP_Salary_CodeOnly_GHsafe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ddbf846",
      "metadata": {
        "id": "5ddbf846"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === MVP Salary — Code-Only Notebook (auto-run) ===\n",
        "# This notebook loads data from GitHub, prepares it, performs EDA, trains/compares regression models,\n",
        "# exposes an auto-updating prediction UI (ipywidgets), and shows an optional confusion matrix (didactic).\n",
        "\n",
        "# ---------------------- Imports & Config ----------------------\n",
        "GITHUB_URL = \"https://raw.githubusercontent.com/gabriel-picussa/MVP-de-SSD---Gabriel-Picussa/main/Salary_DatA.xlsx\"\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "except Exception:\n",
        "    !pip -q install ipywidgets\n",
        "    import ipywidgets as widgets\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, requests, io, re\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, confusion_matrix\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8,5)\n",
        "pd.options.mode.copy_on_write = True\n",
        "\n",
        "def to_raw_github_url(url: str) -> str:\n",
        "    if \"github.com\" in url and \"/blob/\" in url:\n",
        "        parts = url.split(\"github.com/\")[-1]\n",
        "        user_repo, rest = parts.split(\"/blob/\", 1)\n",
        "        return f\"https://raw.githubusercontent.com/{user_repo}/{rest}\"\n",
        "    return url\n",
        "\n",
        "# ---------------------- Load Data (auto) ----------------------\n",
        "RAW = to_raw_github_url(GITHUB_URL)\n",
        "print(\"Lendo:\", RAW)\n",
        "resp = requests.get(RAW, timeout=30)\n",
        "resp.raise_for_status()\n",
        "df = pd.read_excel(io.BytesIO(resp.content))\n",
        "print(\"Dimensões:\", df.shape)\n",
        "display(df.head())\n",
        "\n",
        "# ---------------------- Prep & Harmonization ----------------------\n",
        "def prep_df(df):\n",
        "    df = df.copy()\n",
        "    df.columns = [str(c).strip().replace(' ', '_').replace('-', '_') for c in df.columns]\n",
        "    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    categorical_cols = [c for c in df.columns if c not in numeric_cols]\n",
        "    df[numeric_cols] = df[numeric_cols].apply(lambda s: s.fillna(s.median()))\n",
        "    for c in categorical_cols:\n",
        "        df[c] = df[c].astype(str).fillna('Missing').replace({'nan':'Missing'})\n",
        "    col = 'Education_Level' if 'Education_Level' in df.columns else ('education_level' if 'education_level' in df.columns else None)\n",
        "    def normalize_edu(v: str) -> str:\n",
        "        t = str(v).strip()\n",
        "        low = t.lower().replace(\"degree\",\"\").replace(\".\",\"\").replace(\" \", \"\").replace(\"'\", \"\")\n",
        "        if \"bachelor\" in low: return \"Bachelor's\"\n",
        "        if \"master\"  in low: return \"Master's\"\n",
        "        if \"phd\" in low or \"doutor\" in low: return \"PhD\"\n",
        "        return t\n",
        "    if col: df[col] = df[col].apply(normalize_edu)\n",
        "    return df\n",
        "\n",
        "df = prep_df(df)\n",
        "print(\"Colunas:\", list(df.columns))\n",
        "for c in ['Education_Level','education_level']:\n",
        "    if c in df.columns:\n",
        "        print(c, \"→\", sorted(df[c].unique().tolist()))\n",
        "display(df.head())\n",
        "\n",
        "# ---------------------- Target & Features ----------------------\n",
        "def guess_target(cols):\n",
        "    cands = [c for c in cols if re.search(r\"salary|remun|pay|wage\", str(c), re.I)]\n",
        "    for c in cands:\n",
        "        if re.search(r\"usd|annual|year\", str(c), re.I): return c\n",
        "    return cands[0] if cands else cols[0]\n",
        "\n",
        "TARGET = guess_target(list(df.columns))\n",
        "FEATURES = [c for c in df.columns if c != TARGET]\n",
        "print(\"TARGET =\", TARGET)\n",
        "print(\"FEATURES =\", FEATURES)\n",
        "\n",
        "# ---------------------- EDA (auto) ----------------------\n",
        "def find_col_like(patterns, prefer_numeric=True):\n",
        "    for c in df.columns:\n",
        "        lc = c.lower()\n",
        "        if any(p in lc for p in patterns):\n",
        "            if not prefer_numeric or pd.api.types.is_numeric_dtype(df[c]):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "def trendline(ax, x, y):\n",
        "    m, b = np.polyfit(x, y, 1)\n",
        "    xx = np.linspace(x.min(), x.max(), 100)\n",
        "    yy = m*xx + b\n",
        "    ax.plot(xx, yy)\n",
        "\n",
        "plt.figure(); plt.hist(df[TARGET].dropna(), bins=30); plt.title(f\"Distribuição do alvo: {TARGET}\"); plt.xlabel(TARGET); plt.ylabel(\"Frequência\"); plt.show()\n",
        "plt.figure(); plt.boxplot(df[TARGET].dropna(), labels=[TARGET]); plt.title(f\"Boxplot do alvo: {TARGET}\"); plt.show()\n",
        "\n",
        "cat_feats = [c for c in FEATURES if not pd.api.types.is_numeric_dtype(df[c])]\n",
        "for c in cat_feats[:2]:\n",
        "    top = df[c].value_counts().head(10).index\n",
        "    sub = df[df[c].isin(top)]\n",
        "    means = sub.groupby(c)[TARGET].mean().sort_values(ascending=False)\n",
        "    plt.figure(); means.plot(kind='bar'); plt.title(f\"Média de {TARGET} por {c} (Top 10)\"); plt.xlabel(c); plt.ylabel(f\"Média de {TARGET}\")\n",
        "    plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()\n",
        "\n",
        "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "if len(num_cols) >= 2:\n",
        "    corr = df[num_cols].corr()\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(corr, aspect='auto'); fig.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    ax.set_title(\"Matriz de correlação (com valores)\")\n",
        "    ax.set_xticks(range(len(num_cols))); ax.set_yticks(range(len(num_cols)))\n",
        "    ax.set_xticklabels(num_cols, rotation=90); ax.set_yticklabels(num_cols)\n",
        "    for i in range(len(num_cols)):\n",
        "        for j in range(len(num_cols)):\n",
        "            ax.text(j, i, f\"{corr.iloc[i,j]:.2f}\", ha='center', va='center', fontsize=8)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "age_col = find_col_like(['age'])\n",
        "exp_col = find_col_like(['experience','years','yoe','exp'])\n",
        "if age_col and exp_col and pd.api.types.is_numeric_dtype(df[age_col]) and pd.api.types.is_numeric_dtype(df[exp_col]):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(df[age_col], df[exp_col])\n",
        "    trendline(ax, df[age_col].values, df[exp_col].values)\n",
        "    ax.set_title(f\"{age_col} × {exp_col} (com linha de tendência)\"); ax.set_xlabel(age_col); ax.set_ylabel(exp_col)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "if exp_col and pd.api.types.is_numeric_dtype(df[exp_col]):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(df[exp_col], df[TARGET])\n",
        "    trendline(ax, df[exp_col].values, df[TARGET].values)\n",
        "    ax.set_title(f\"{exp_col} × {TARGET} (com linha de tendência)\"); ax.set_xlabel(exp_col); ax.set_ylabel(TARGET)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---------------------- Modeling (auto) ----------------------\n",
        "data = df.dropna(subset=[TARGET]).copy()\n",
        "X = data[FEATURES].copy()\n",
        "y = data[TARGET].astype(float)\n",
        "\n",
        "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "prep = ColumnTransformer([('num', StandardScaler(), num_cols),\n",
        "                          ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)])\n",
        "\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=42, n_estimators=300),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([('prep', prep), ('model', model)])\n",
        "    pipe.fit(Xtr, ytr)\n",
        "    p = pipe.predict(Xte)\n",
        "    r2 = r2_score(yte, p)\n",
        "    mse = mean_squared_error(yte, p)\n",
        "    rmse = float(np.sqrt(mse))\n",
        "    mae = mean_absolute_error(yte, p)\n",
        "    results.append((name, pipe, r2, rmse, mae))\n",
        "\n",
        "grid = GridSearchCV(Pipeline([('prep', prep), ('model', GradientBoostingRegressor(random_state=42))]),\n",
        "                    {'model__n_estimators':[100,200], 'model__learning_rate':[0.05,0.1], 'model__max_depth':[2,3]},\n",
        "                    scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "grid.fit(Xtr, ytr)\n",
        "p = grid.best_estimator_.predict(Xte)\n",
        "r2 = r2_score(yte, p); rmse = float(np.sqrt(mean_squared_error(yte, p))); mae = mean_absolute_error(yte, p)\n",
        "results.append((\"GradientBoosting(GridSearch)\", grid.best_estimator_, r2, rmse, mae))\n",
        "\n",
        "results_sorted = sorted(results, key=lambda x: x[3])\n",
        "print(\"Resultados (ordenado por RMSE):\")\n",
        "for n, _, r2, rmse, mae in results_sorted:\n",
        "    print(f\"{n:30s}  R²={r2:.3f}  RMSE={rmse:.3f}  MAE={mae:.3f}\")\n",
        "\n",
        "labels = [r[0] for r in results_sorted]\n",
        "r2_vals = [r[2] for r in results_sorted]\n",
        "rmse_vals = [r[3] for r in results_sorted]\n",
        "mae_vals = [r[4] for r in results_sorted]\n",
        "\n",
        "plt.figure(); plt.bar(labels, r2_vals); plt.title(\"R²\"); plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
        "plt.figure(); plt.bar(labels, rmse_vals); plt.title(\"RMSE\"); plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
        "plt.figure(); plt.bar(labels, mae_vals); plt.title(\"MAE\"); plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
        "\n",
        "BEST_NAME, BEST_PIPE = results_sorted[0][0], results_sorted[0][1]\n",
        "print(\"Melhor (RMSE):\", BEST_NAME)\n",
        "\n",
        "# ---------------------- Prediction UI (auto-update) ----------------------\n",
        "def build_controls(features):\n",
        "    ctrls = []\n",
        "    for c in features:\n",
        "        if pd.api.types.is_numeric_dtype(df[c]):\n",
        "            lo, hi = float(df[c].quantile(0.05)), float(df[c].quantile(0.95))\n",
        "            step = (hi-lo)/100 if hi>lo else 1.0\n",
        "            if pd.api.types.is_float_dtype(df[c]):\n",
        "                w = widgets.FloatSlider(description=c, min=lo, max=hi if hi>lo else lo+1, step=step, value=float(df[c].median()), continuous_update=True)\n",
        "            else:\n",
        "                w = widgets.IntSlider(description=c, min=int(lo), max=int(hi) if hi>lo else int(lo)+1, step=max(1,int(step)), value=int(df[c].median()), continuous_update=True)\n",
        "        else:\n",
        "            opts = sorted(df[c].astype(str).unique().tolist())\n",
        "            w = widgets.Dropdown(description=c, options=opts, value=opts[0] if opts else None)\n",
        "        ctrls.append(w)\n",
        "    return ctrls\n",
        "\n",
        "controls = build_controls(FEATURES)\n",
        "box = widgets.VBox(controls)\n",
        "out = widgets.Output()\n",
        "\n",
        "def update_prediction(change=None):\n",
        "    data = {c.description:[c.value] for c in controls}\n",
        "    Xnew = pd.DataFrame(data)\n",
        "    yhat = BEST_PIPE.predict(Xnew)[0]\n",
        "    out.clear_output()\n",
        "    with out:\n",
        "        print(f\"Previsão de salário: {yhat:,.2f}\")\n",
        "\n",
        "for c in controls:\n",
        "    if hasattr(c, 'observe'):\n",
        "        c.observe(update_prediction, names='value')\n",
        "\n",
        "display(box, out)\n",
        "update_prediction()\n",
        "\n",
        "# ---------------------- Optional: Confusion Matrix (didactic) ----------------------\n",
        "y_cont = data[TARGET].astype(float).values\n",
        "bins = np.quantile(y_cont, np.linspace(0,1,4))  # 3 bins\n",
        "bins[0] -= 1e-6; bins[-1] += 1e-6\n",
        "y_cat = np.digitize(y_cont, bins[1:-1])\n",
        "Xc = data[FEATURES].copy()\n",
        "\n",
        "num_cols = [c for c in Xc.columns if pd.api.types.is_numeric_dtype(Xc[c])]\n",
        "cat_cols = [c for c in Xc.columns if c not in num_cols]\n",
        "prep_c = ColumnTransformer([('num', StandardScaler(), num_cols), ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(Xc, y_cat, test_size=0.2, random_state=42)\n",
        "clf = Pipeline([('prep', prep_c), ('model', RandomForestClassifier(random_state=42, n_estimators=300))])\n",
        "clf.fit(Xtr, ytr)\n",
        "yp = clf.predict(Xte)\n",
        "\n",
        "cm = confusion_matrix(yte, yp, labels=[0,1,2])\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, cmap='Blues')\n",
        "ax.set_title(\"Matriz de confusão (bins do target)\"); ax.set_xlabel(\"Predito\"); ax.set_ylabel(\"Verdadeiro\")\n",
        "ax.set_xticks([0,1,2]); ax.set_yticks([0,1,2])\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax.text(j, i, str(cm[i,j]), ha='center', va='center')\n",
        "fig.colorbar(im, fraction=0.046, pad=0.04)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}